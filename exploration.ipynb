{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration of FakeNewsCorpus sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRUMP AND FAKE NEWS\n",
    "# number of the use of the word 'trump' for every type of news\n",
    "#print(\"Number of the use of the word 'trump' for every type of news: \")\n",
    "#print(Copy_stemming['content'].astype(str).str.count('trump').groupby(Copy_stemming['type']).sum())\n",
    "\n",
    "#print(\"% of the use of the word 'trump' in fake news articles: \")\n",
    "#print(Copy_stemming['content'].astype(str).str.count('trump').groupby(Copy_stemming['type']).sum()['fake']/Copy_stemming['content'].astype(str).str.count('trump').sum()*100)\n",
    "\n",
    "# DISTRIBUTION OF THE NUMBER OF ARTICLES FOR EVERY TYPE OF NEWS IN DATASET\n",
    "print(\"Number of articles for every type of news: \")\n",
    "print(Copy_stemming['content'].astype(str).groupby(Copy_stemming['type']).count())\n",
    "\n",
    "print(\"_______________________________\")\n",
    "# AUTHOR OF ARTICLES OF ONE TYPE OF NEWS AND HOW MANY THEY HAVE WRITTEN\n",
    "def Authors (news_type): \n",
    "    p = {}\n",
    "    for i in range(len(Copy_stemming['type'])):\n",
    "        if Copy_stemming['type'][i] == news_type:\n",
    "            if Copy_stemming['authors'][i] not in p:\n",
    "                # put it in the dictionary\n",
    "                p[Copy_stemming['authors'][i]] = 1\n",
    "            else:\n",
    "                # increment the counter\n",
    "                p[Copy_stemming['authors'][i]] += 1\n",
    "    return dict(sorted(p.items(), key = lambda kv: kv[1], reverse=True))\n",
    "\n",
    "print(\"Author of articles of type 'fake' and how many they have written: \")\n",
    "print(Authors('fake'))\n",
    "\n",
    "# how many articles has author 'John Rolls'\n",
    "print(\"How many articles has author 'John Rolls': \")\n",
    "print(Copy_stemming['content'].astype(str).groupby(Copy_stemming['authors']).count()['John Rolls'])\n",
    "\n",
    "print(\"_______________________________\")\n",
    "# DOMAIN OF THE ARTICLES OF EACH TYPE OF NEWS\n",
    "def domains(newstype):\n",
    "    k = {}\n",
    "    for i in range(len(Copy_stemming['type'])):\n",
    "        if Copy_stemming['type'][i] == newstype:\n",
    "            if Copy_stemming['domain'][i] not in k:\n",
    "                # put it in the dictionary\n",
    "                k[Copy_stemming['domain'][i]] = 1\n",
    "            else:\n",
    "                # increment the counter\n",
    "                k[Copy_stemming['domain'][i]] += 1\n",
    "    return k\n",
    "\n",
    "## AVERAGE NUMBER OF WORDS IN THE ARTICLES OF EACH TYPE OF NEWS\n",
    "def average_wordcounts(newstype):\n",
    "    n = []\n",
    "    for i in range(len(Copy_stemming['type'])):\n",
    "        if Copy_stemming['type'][i] == newstype:\n",
    "            n.append(len(Copy_stemming['content'][i]))\n",
    "    return (sum(n)/len(n))\n",
    "\n",
    "Av_wordcount_conspiracy = average_wordcounts('conspiracy') #462.42 words\n",
    "Av_wordcount_reliable = average_wordcounts('reliable') #256.7 words\n",
    "Av_wordcount_fake = average_wordcounts('fake') #376.75 words\n",
    "Av_wordcount_unreliable = average_wordcounts('unreliable') #180.0 words\n",
    "Av_wordcount_junksci = average_wordcounts('junksci') #218.7 words\n",
    "Av_wordcount_bias = average_wordcounts('bias') #256.7 words\n",
    "Av_wordcount_political = average_wordcounts('political') #367.69 words\n",
    "Av_wordcount_unknown = average_wordcounts('unknown') \n",
    "Av_wordcount_hate = 0 \n",
    "Av_wordcount_rumor = 0\n",
    "\n",
    "# 'fake', 'conspiracy', 'junksci', 'hate', 'unreliable', 'rumor'\n",
    "fake = (Av_wordcount_fake + Av_wordcount_conspiracy + Av_wordcount_junksci + Av_wordcount_unreliable)/4\n",
    "non_fake = (Av_wordcount_reliable + Av_wordcount_bias + Av_wordcount_political)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "type_news = ['reliable', 'bias', 'unreliable', 'fake', 'conspiracy', 'political', 'junksi']\n",
    "average_wordcount = [256.7, 256.7, 180.0, 376.75, 462.42, 367.69, 218.7]\n",
    "\n",
    "ax.set_title('Average word count for the different types of articles', fontsize=12, fontweight='bold') # title\n",
    "ax.set_ylabel('Average word count for article') # y-axis label\n",
    "ax.set_xlabel('Type of news') # x-axis label\n",
    "ax.bar(type_news, average_wordcount, color=['green'])\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "type_news = ['fake', 'non-fake']\n",
    "average_wordcount = [fake, non_fake]\n",
    "\n",
    "ax.set_title('Average word count for fake and non-fake articles', fontsize=12, fontweight='bold') # title\n",
    "ax.set_ylabel('Average word count for article') # y-axis label\n",
    "ax.set_xlabel('Type of news') # x-axis label\n",
    "\n",
    "ax.bar(type_news, average_wordcount, color=[(0.5, 0, 0, 0.8), (0, 0.4, 0, 0.8)])\n",
    "fig.set_size_inches(4, 4)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
